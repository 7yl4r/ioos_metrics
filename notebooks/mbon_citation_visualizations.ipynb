{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173f78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: import IOOS metrics citation data helper function\n",
    "# TODO: can import this from ioos_metrics. it was copy-pasted here.\n",
    "# ref https://github.com/ioos/ioos_metrics/\n",
    "def mbon_stats():\n",
    "    \"\"\"\n",
    "    This function collects download statistics about MBON affiliated datasets shared with the Ocean Biodiversity\n",
    "    Information System (OBIS) and the Global Biodiversity Information Framework (GBIF). The function returns a\n",
    "    dataframe with rows corresponding to each dataset.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import pyobis\n",
    "    import urllib.parse\n",
    "\n",
    "    # collect dataset information from OBIS\n",
    "    institution_id = 23070\n",
    "    query = pyobis.dataset.search(instituteid=institution_id)\n",
    "    df = pd.DataFrame(query.execute())\n",
    "    df_obis = pd.DataFrame.from_records(df[\"results\"])\n",
    "    df_obis.columns = ['obis_' + str(col) for col in df_obis.columns]\n",
    "\n",
    "    df_mapping = pd.DataFrame()\n",
    "    base_url = 'https://api.gbif.org'\n",
    "    # iterate through each OBIS dataset to gather uuid from GBIF\n",
    "    # create a mapping table\n",
    "    for title in df_obis['obis_title']:\n",
    "        string = title\n",
    "        query = '{}/v1/dataset/search?q={}'.format(base_url, urllib.parse.quote(string))\n",
    "        df = pd.read_json(query, orient='index').T\n",
    "\n",
    "        # build a DataFrame with the info we need more accessible\n",
    "        df_mapping = pd.concat([df_mapping, pd.DataFrame({\n",
    "            'gbif_uuid': df['results'].values[0][0]['key'],\n",
    "            'title': [df['results'].values[0][0]['title']],\n",
    "            'obis_id': [df_obis.loc[df_obis['obis_title']==title,'obis_id'].to_string(index=False)],\n",
    "            'doi': [df['results'].values[0][0]['doi']]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    df_gbif = pd.DataFrame()\n",
    "    for key in df_mapping['gbif_uuid']:\n",
    "\n",
    "        url = 'https://api.gbif.org/v1/literature/export?format=CSV&gbifDatasetKey={}'.format(key)\n",
    "        df2 = pd.read_csv(url)  # collect liturature cited information\n",
    "        df2.columns = ['literature_' + str(col) for col in df2.columns]\n",
    "        df2['gbif_uuid'] = key\n",
    "\n",
    "        df_gbif = pd.concat([df2,df_gbif], ignore_index=True)\n",
    "\n",
    "    # merge the OBIS and GBIF data frames together\n",
    "    df_obis = df_obis.merge(df_mapping, on='obis_id')\n",
    "\n",
    "    df_out = df_gbif.merge(df_obis, on='gbif_uuid')\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e2ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: fetch the latest mbon data\n",
    "stats_df = mbon_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d246f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: define streamgraph function\n",
    "def make_streamgraph(og_df, y_colname, plt_title):\n",
    "  # subset the df to save RAM\n",
    "  df_subset = og_df[[y_colname, 'literature_published']]\n",
    "  # split any pipe-delimited rows in y_colname\n",
    "  df = df_subset.assign(**{y_colname: df_subset[y_colname].str.split('|')}).explode(y_colname)\n",
    "  # Convert the 'literature_published' column to datetime\n",
    "  df['literature_published'] = pd.to_datetime(df['literature_published'])\n",
    "  \n",
    "  # Extract month and year for aggregation\n",
    "  df['year_month'] = df['literature_published'].dt.to_period('M')\n",
    "  \n",
    "  # Group by year_month and title, then get the cumulative count\n",
    "  df['count'] = df.groupby(y_colname).cumcount() + 1\n",
    "  monthly_counts = df.groupby(['year_month', y_colname]).agg({'count': 'max'}).reset_index()\n",
    "  \n",
    "  # Pivot the DataFrame to have year_month as rows and titles as columns\n",
    "  pivot_df = monthly_counts.pivot(index='year_month', columns=y_colname, values='count').fillna(0).cumsum()\n",
    "  \n",
    "  # Plotting the streamgraph\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plt.stackplot(pivot_df.index.to_timestamp(), pivot_df.T, labels=pivot_df.columns)\n",
    "  plt.title(plt_title)\n",
    "  plt.xlabel('Date')\n",
    "  plt.ylabel('Cumulative Count')\n",
    "  plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278a8531",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1548083018.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    make_streamgraph(stats_df, \"obis_title\", f'Citation Count by MBON Dataset\")\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: streamgraph of citations per dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import streamz\n",
    "\n",
    "make_streamgraph(stats_df, \"obis_title\", f'Citation Count by MBON Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: streamgraph of citations per topic\n",
    "# split up column with pipe-delimited multi-values\n",
    "\n",
    "make_streamgraph(stats_df, \"literature_topics\", \"MBON Dataset Contributions to Topic Citations\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5dc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: create chlopleth map \n",
    "import plotly.express as px\n",
    "\n",
    "loc_colname = \"literature_countries_of_researcher\"\n",
    "og_df = stats_df[[loc_colname]]\n",
    "\n",
    "# split any pipe-delimited rows in y_colname\n",
    "df = og_df.assign(**{loc_colname: og_df[loc_colname].str.split('|')}).explode(loc_colname)\n",
    "\n",
    "# Count the occurrences of each country\n",
    "country_counts = df[loc_colname].value_counts().reset_index()\n",
    "country_counts.columns = ['Country', 'Count']\n",
    "\n",
    "# Create the choropleth map with a monochrome color scale and gray for missing data\n",
    "fig = px.choropleth(country_counts,\n",
    "                    locations=\"Country\",\n",
    "                    locationmode='country names',\n",
    "                    color=\"Count\",\n",
    "                    hover_name=\"Country\",\n",
    "                    color_continuous_scale=px.colors.sequential.Blues,\n",
    "                    title='Choropleth Heatmap of # Citations in each Country\"\n",
    "  )\n",
    "\n",
    "# Update layout to set color for missing data\n",
    "fig.update_geos(\n",
    "    showcoastlines=True, coastlinecolor=\"Gray\",\n",
    "    showland=True, landcolor=\"White\",\n",
    "    showocean=True, oceancolor=\"Gray\",\n",
    "    showlakes=True, lakecolor=\"Gray\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230cd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
